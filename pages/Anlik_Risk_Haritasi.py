# pages/Anlik_Risk_Haritasi.py
# SUTAM â€” AnlÄ±k Risk HaritasÄ± (ANLIK â€¢ SF saatine gÃ¶re hour_range)
# - Likert (1-5): SEÃ‡Ä°LÄ° saat dilimindeki risk daÄŸÄ±lÄ±mÄ±na gÃ¶re (quantile / "Ã§an eÄŸrisi" mantÄ±ÄŸÄ±)
# - Tooltip: GEOID + Risk seviyesi + p_event + expected + top1-3 + mikro kolluk Ã¶nerisi
# - SeÃ§ili hÃ¼cre analizi yok (kaldÄ±rÄ±ldÄ±)
# - Legend: %0-20 ... %80-100 (saat dilimi iÃ§i gÃ¶reli)

from __future__ import annotations

import os, json
from datetime import datetime
from zoneinfo import ZoneInfo

import numpy as np
import pandas as pd
import streamlit as st
import pydeck as pdk

# --- GÃ¼venli import ---
try:
    from src.io_data import load_parquet_or_csv, prepare_forecast
except Exception as e:
    load_parquet_or_csv = None
    prepare_forecast = None
    _IMPORT_SRC_ERR = e
else:
    _IMPORT_SRC_ERR = None

DATA_DIR = os.getenv("DATA_DIR", "data").rstrip("/")
FC_CANDIDATES = [
    f"{DATA_DIR}/forecast_7d.parquet",
    f"{DATA_DIR}/full_fc.parquet",
    "data/forecast_7d.parquet",
    "deploy/full_fc.parquet",
    "data/full_fc.parquet",
]
GEOJSON_PATH = os.getenv("GEOJSON_PATH", "data/sf_cells.geojson")
TARGET_TZ = "America/Los_Angeles"

# Renkler (kurumsal-yumuÅŸak)
LIKERT = {
    1: ("Ã‡ok DÃ¼ÅŸÃ¼k",  [56, 189, 137]),
    2: ("DÃ¼ÅŸÃ¼k",      [104, 207, 162]),
    3: ("Orta",       [241, 196, 15]),
    4: ("YÃ¼ksek",     [235, 147, 80]),
    5: ("Ã‡ok YÃ¼ksek", [220, 88, 76]),
}
DEFAULT_FILL = [220, 220, 220]

# --- helpers ---
def _first_existing(paths: list[str]) -> str | None:
    for p in paths:
        if os.path.exists(p):
            return p
    return None

def digits11(x) -> str:
    s = "".join(ch for ch in str(x) if ch.isdigit())
    return s.zfill(11) if s else ""

def _pick_col(df: pd.DataFrame, candidates: list[str]) -> str | None:
    cols = {c.lower(): c for c in df.columns}
    for k in candidates:
        if k.lower() in cols:
            return cols[k.lower()]
    return None

def _safe_float(x, default=np.nan) -> float:
    try:
        return float(x)
    except Exception:
        return default

def _fmt3(x) -> str:
    v = _safe_float(x, np.nan)
    return "â€”" if not np.isfinite(v) else f"{v:.3f}"

def _fmt_expected_band(x) -> str:
    v = _safe_float(x, np.nan)
    if not np.isfinite(v):
        return "â€”"
    v = max(0.0, v)
    lo = int(np.floor(v))
    hi = int(np.ceil(v))
    return f"~{lo}" if lo == hi else f"~{lo}â€“{hi}"

def _parse_range(tok: str):
    if not isinstance(tok, str) or "-" not in tok:
        return None
    a, b = tok.split("-", 1)
    try:
        s = int(a.strip()); e = int(b.strip())
    except Exception:
        return None
    s = max(0, min(23, s))
    e = max(1, min(24, e))
    return (s, e)

def _hour_to_bucket(h: int, labels: list[str]) -> str | None:
    parsed = []
    for lab in labels:
        rg = _parse_range(str(lab))
        if rg:
            parsed.append((str(lab), rg[0], rg[1]))
    for lab, s, e in parsed:
        if s <= h < e:
            return lab
    for lab, s, e in parsed:
        if s > e and (h >= s or h < e):
            return lab
    return parsed[0][0] if parsed else None

# --- loaders ---
@st.cache_data(show_spinner=False)
def load_forecast() -> pd.DataFrame:
    p = _first_existing(FC_CANDIDATES)
    if not p or load_parquet_or_csv is None:
        return pd.DataFrame()
    fc = load_parquet_or_csv(p)
    if fc is None or getattr(fc, "empty", True):
        return pd.DataFrame()

    if prepare_forecast is not None:
        try:
            fc = prepare_forecast(fc, gp=None)
        except TypeError:
            pass
        except Exception:
            pass
    return fc

@st.cache_data(show_spinner=False)
def load_geojson() -> dict:
    if os.path.exists(GEOJSON_PATH):
        with open(GEOJSON_PATH, "r", encoding="utf-8") as f:
            return json.load(f)
    return {}

# --- risk to likert (SADECE saat dilimi iÃ§inde quantile) ---
def compute_relative_likert(df_hr: pd.DataFrame) -> tuple[pd.Series, str]:
    """
    Likert'i o saat dilimindeki daÄŸÄ±lÄ±ma gÃ¶re 5'e bÃ¶ler.
    Ã–ncelik: risk_score -> risk_prob -> p_event
    """
    col = _pick_col(df_hr, ["risk_score", "risk_prob", "p_event"])
    if not col:
        return pd.Series([3] * len(df_hr), index=df_hr.index), "risk_score/risk_prob/p_event yok"

    vals = pd.to_numeric(df_hr[col], errors="coerce")
    if vals.notna().sum() < 10:
        # Ã§ok az veri varsa sabit orta
        return pd.Series([3] * len(df_hr), index=df_hr.index), f"{col} az veri"

    # qcut aynÄ± deÄŸerlerde hata verebilir -> rank ile stabilize
    ranked = vals.rank(method="first")
    try:
        bins = pd.qcut(ranked, 5, labels=[1, 2, 3, 4, 5])
        return bins.astype(int), f"quantile({col})"
    except Exception:
        # fallback: percentiles manual
        q = np.nanpercentile(vals, [20, 40, 60, 80])
        out = pd.Series(3, index=df_hr.index)
        out[vals <= q[0]] = 1
        out[(vals > q[0]) & (vals <= q[1])] = 2
        out[(vals > q[1]) & (vals <= q[2])] = 3
        out[(vals > q[2]) & (vals <= q[3])] = 4
        out[vals > q[3]] = 5
        return out.astype(int), f"percentile({col})"

def micro_ops_text(likert: int) -> str:
    # KÄ±sa, doÄŸrudan, â€œemirâ€ gibi olmayan dil
    if likert >= 5:
        return "Ã–neri: Kritik yoÄŸunluk gÃ¶rÃ¼lebilir. GÃ¶rÃ¼nÃ¼r devriye ve giriÅŸâ€“Ã§Ä±kÄ±ÅŸ akslarÄ±nda kÄ±sa sÃ¼reli yoÄŸunlaÅŸtÄ±rma deÄŸerlendirilebilir."
    if likert == 4:
        return "Ã–neri: Risk artÄ±ÅŸÄ± olabilir. Transit/ana arter Ã§evresinde kÄ±sa kontrollÃ¼ tur planlanabilir."
    if likert == 3:
        return "Ã–neri: Rutin devriye yeterli; anomali gÃ¶zlemi odaklÄ± izleme yapÄ±labilir."
    if likert == 2:
        return "Ã–neri: DÃ¼ÅŸÃ¼k risk; standart devriye ve caydÄ±rÄ±cÄ±lÄ±k odaklÄ± dolaÅŸÄ±m uygundur."
    return "Ã–neri: Ã‡ok dÃ¼ÅŸÃ¼k risk; rutin gÃ¶rÃ¼nÃ¼rlÃ¼k korunabilir."

def render_legend_compact():
    # â€œhoverâ€ cÃ¼mlesi yerine yÃ¼zde dilimleri
    with st.popover("ğŸ¨ Risk Ã–lÃ§eÄŸi", use_container_width=False):
        st.markdown("**Bu saat dilimi iÃ§inde gÃ¶reli sÄ±nÄ±flandÄ±rma**")
        st.caption("Risk seviyeleri, seÃ§ili tarih+saat dilimindeki tÃ¼m hÃ¼crelerin risk skorlarÄ± daÄŸÄ±lÄ±mÄ± %20â€™lik dilimlere bÃ¶lÃ¼nerek hesaplanÄ±r.")
        items = [
            (1, "Ã‡ok DÃ¼ÅŸÃ¼k", "0â€“20"),
            (2, "DÃ¼ÅŸÃ¼k", "20â€“40"),
            (3, "Orta", "40â€“60"),
            (4, "YÃ¼ksek", "60â€“80"),
            (5, "Ã‡ok YÃ¼ksek", "80â€“100"),
        ]
        for k, label, pct in items:
            rgb = LIKERT[k][1]
            st.markdown(
                f"""
                <div style="display:flex; align-items:center; justify-content:space-between; gap:12px; margin:8px 0;">
                  <div style="display:flex; align-items:center; gap:10px;">
                    <div style="width:14px;height:14px;border-radius:5px;background:rgb({rgb[0]},{rgb[1]},{rgb[2]});"></div>
                    <div><b>{k}</b> â€” {label}</div>
                  </div>
                  <div style="opacity:0.75;">%{pct}</div>
                </div>
                """,
                unsafe_allow_html=True,
            )
        st.caption("Not: Bu Ã¶lÃ§ek mutlak eÅŸik deÄŸildir; aynÄ± saat dilimindeki hÃ¼crelerin birbirine gÃ¶re konumunu gÃ¶sterir.")

def enrich_geojson(gj: dict, df_hr: pd.DataFrame) -> dict:
    if not gj or df_hr.empty:
        return gj

    df = df_hr.copy()

    # GEOID
    geoid_col = _pick_col(df, ["GEOID", "geoid"])
    df["geoid"] = df[geoid_col].map(digits11) if geoid_col else ""

    # p & expected
    pe = _pick_col(df, ["p_event", "risk_prob"])
    ex = _pick_col(df, ["expected_count", "expected_crimes"])
    df["_p_event"] = pd.to_numeric(df[pe], errors="coerce") if pe else np.nan
    df["_expected"] = pd.to_numeric(df[ex], errors="coerce") if ex else np.nan
    df["p_event_txt"] = df["_p_event"].map(_fmt3)
    df["expected_txt"] = df["_expected"].map(_fmt_expected_band)

    # top cats
    t1 = _pick_col(df, ["top1_category", "top1_cat", "cat1"])
    t2 = _pick_col(df, ["top2_category", "top2_cat", "cat2"])
    t3 = _pick_col(df, ["top3_category", "top3_cat", "cat3"])

    def _clean(s: pd.Series) -> pd.Series:
        return s.astype(str).replace("nan", "").replace("None", "").fillna("")

    df["top1_category"] = _clean(df[t1]) if t1 else ""
    df["top2_category"] = _clean(df[t2]) if t2 else ""
    df["top3_category"] = _clean(df[t3]) if t3 else ""

    # âœ… SADECE BU SAAT DÄ°LÄ°MÄ° Ä°Ã‡Ä°N: gÃ¶reli likert
    df["risk_likert"], _method = compute_relative_likert(df)
    df["likert_label"] = df["risk_likert"].map(lambda k: LIKERT[int(k)][0] if int(k) in LIKERT else "Orta")
    df["fill_color"] = df["risk_likert"].map(lambda k: LIKERT[int(k)][1] if int(k) in LIKERT else DEFAULT_FILL)

    # mikro Ã¶neri tooltip iÃ§ine
    df["ops_tip"] = df["risk_likert"].map(lambda k: micro_ops_text(int(k)))

    # tekilleÅŸtir
    df["_exp_num"] = pd.to_numeric(df["_expected"], errors="coerce").fillna(0.0)
    df = df.sort_values(["risk_likert", "_exp_num"], ascending=[False, False]).drop_duplicates("geoid", keep="first")
    dmap = df.set_index("geoid")

    feats_out = []
    for feat in gj.get("features", []):
        props = dict(feat.get("properties") or {})

        raw = None
        for k in ("geoid", "GEOID", "cell_id", "id", "geoid11", "geoid_11", "display_id"):
            if k in props:
                raw = props[k]
                break
        if raw is None:
            for k, v in props.items():
                if "geoid" in str(k).lower():
                    raw = v
                    break

        key = digits11(raw)
        props["display_id"] = str(raw) if raw not in (None, "") else key

        # defaults
        props["likert_label"] = ""
        props["p_event_txt"] = "â€”"
        props["expected_txt"] = "â€”"
        props["top1_category"] = ""
        props["top2_category"] = ""
        props["top3_category"] = ""
        props["ops_tip"] = ""
        props["fill_color"] = DEFAULT_FILL

        if key and key in dmap.index:
            row = dmap.loc[key]
            props["likert_label"] = str(row.get("likert_label") or "")
            props["p_event_txt"] = str(row.get("p_event_txt") or "â€”")
            props["expected_txt"] = str(row.get("expected_txt") or "â€”")
            props["top1_category"] = str(row.get("top1_category") or "")
            props["top2_category"] = str(row.get("top2_category") or "")
            props["top3_category"] = str(row.get("top3_category") or "")
            props["ops_tip"] = str(row.get("ops_tip") or "")
            props["fill_color"] = row.get("fill_color", DEFAULT_FILL)

        feats_out.append({**feat, "properties": props})

    return {**gj, "features": feats_out}

def draw_map(gj: dict):
    layer = pdk.Layer(
        "GeoJsonLayer",
        gj,
        stroked=True,
        get_line_color=[80, 80, 80],
        line_width_min_pixels=0.6,
        filled=True,
        get_fill_color="properties.fill_color",
        pickable=True,
        opacity=0.65,
    )
    tooltip = {
        "html": (
            "<b>GEOID:</b> {display_id}"
            "<br/><b>Risk Seviyesi:</b> {likert_label}"
            "<br/><b>SuÃ§ olasÄ±lÄ±ÄŸÄ± (p):</b> {p_event_txt}"
            "<br/><b>Beklenen suÃ§ sayÄ±sÄ±:</b> {expected_txt}"
            "<hr style='opacity:0.28'/>"
            "<b>En olasÄ± 3 suÃ§:</b>"
            "<br/>â€¢ {top1_category}"
            "<br/>â€¢ {top2_category}"
            "<br/>â€¢ {top3_category}"
            "<hr style='opacity:0.28'/>"
            "<b>Kolluk Notu:</b><br/>{ops_tip}"
        ),
        "style": {"backgroundColor": "#111827", "color": "white", "maxWidth": "360px"},
    }
    deck = pdk.Deck(
        layers=[layer],
        initial_view_state=pdk.ViewState(latitude=37.7749, longitude=-122.4194, zoom=10),
        map_style="light",
        tooltip=tooltip,
    )
    st.pydeck_chart(deck, use_container_width=True)

def render_anlik_risk_haritasi():
    st.markdown("# AnlÄ±k Risk HaritasÄ±")
    st.caption("San Francisco yerel saatine gÃ¶re mevcut saat dilimindeki risk dÃ¼zeylerini 5â€™li Ã¶lÃ§ekte gÃ¶sterir.")

    if _IMPORT_SRC_ERR is not None:
        st.error("`src.io_data` import edilemedi. `src/` klasÃ¶rÃ¼nÃ¼ ve yollarÄ± kontrol edin.")
        st.code(repr(_IMPORT_SRC_ERR))
        return

    fc = load_forecast()
    if fc.empty:
        st.error("Forecast verisi bulunamadÄ±/boÅŸ. `data/forecast_7d.parquet` veya `deploy/full_fc.parquet` gerekli.")
        return

    date_col = _pick_col(fc, ["date"])
    hr_col = _pick_col(fc, ["hour_range", "hour_bucket"])
    if not date_col or not hr_col:
        st.error("Forecast iÃ§inde `date` ve/veya `hour_range` yok.")
        return

    fc = fc.copy()
    fc[date_col] = pd.to_datetime(fc[date_col], errors="coerce")
    fc["date_norm"] = fc[date_col].dt.normalize()

    now_sf = datetime.now(ZoneInfo(TARGET_TZ))
    today = pd.Timestamp(now_sf.date())

    dates = sorted(fc["date_norm"].dropna().unique())
    if not dates:
        st.error("Forecast iÃ§inde geÃ§erli tarih yok.")
        return

    sel_date = today if today in dates else max([d for d in dates if d <= today], default=dates[0])
    labels = sorted(fc[hr_col].dropna().astype(str).unique().tolist())
    hr_label = _hour_to_bucket(now_sf.hour, labels) or (labels[0] if labels else None)
    if not hr_label:
        st.error("Forecast iÃ§inde hour_range bulunamadÄ±.")
        return

    st.caption(f"SF saati: **{now_sf:%Y-%m-%d %H:%M}** â€¢ Tarih: **{pd.Timestamp(sel_date).date()}** â€¢ Dilim: **{hr_label}**")

    # âœ… Senin istediÄŸin cÃ¼mle (daha dÃ¼zgÃ¼n)
    st.info("Risk Ã¶lÃ§eÄŸi, bu tarih ve saat dilimindeki hÃ¼crelere ait risk skorlarÄ±nÄ±n daÄŸÄ±lÄ±mÄ± temel alÄ±narak gÃ¶reli (%20â€™lik dilimler) ÅŸekilde hesaplanmÄ±ÅŸtÄ±r.")

    # Legend popover (yÃ¼zdeli)
    render_legend_compact()

    df_hr = fc[(fc["date_norm"] == sel_date) & (fc[hr_col].astype(str) == str(hr_label))].copy()
    if df_hr.empty:
        st.warning("Bu tarih/saat dilimi iÃ§in kayÄ±t bulunamadÄ±.")
        return

    gj = load_geojson()
    if not gj:
        st.error(f"GeoJSON bulunamadÄ±: `{GEOJSON_PATH}`")
        return

    gj_enriched = enrich_geojson(gj, df_hr)
    draw_map(gj_enriched)

    # Ä°stersen burada alt kÄ±sma sadece kÄ±sa not bÄ±rak:
    st.caption("Not: Ã‡Ä±ktÄ±lar karar destek amaÃ§lÄ±dÄ±r; saha bilgisi ve amir deÄŸerlendirmesi ile birlikte yorumlanmalÄ±dÄ±r.")
